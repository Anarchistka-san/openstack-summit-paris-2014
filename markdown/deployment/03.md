Corosync/pacemaker manifests: part 2 - stability
==================================================

-	[5.1 release] asymmetric cluster:
	-	services stopped everywhere by default
		-	enabled by 0 location constraint ("unbanning")
		-	clones started locally
		-	primitives started only once

Note:
 Our initial implementation of this provider was not perfect as it was triggering
 restarts not only for the services on the particular node being deployed but
 globally, e.g. for clone resources each resource was restarted. So we switched to
 asymmetric pacemaker cluster which does not start services by default.
 Then we refactored service provider to perform actions locally using pacemaker
 location constraints for start and stop actions. E.g. to enable a service somewhere
 we set zero location score for the particular node which we call "unbanning" of the
 node.  In order to make service actions local-wise we altered status method behaviour depending on the type of resource. If resource is a primitive, then we check if it
 is already started in the cluster and if it is true, we "unban" it and silently exit. If it is false, we wait for status change. If it is a clone or master/slave resource
 then we check local status of the resource do ban/unban and wait for status to change
